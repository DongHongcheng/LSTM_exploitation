import numpy as np
import random
import tensorflow as tf
import matplotlib.pyplot as plt

P = 3
Q = 10


def br(ratio):
    if ratio < P / (P + Q):
        br1 = 0
    else:
        br1 = 1
    return br1


def weight_update(strategy, weight_now):
    weight_next = np.zeros(2)
    if strategy == 1:
        weight_next = weight_now + [1, 0]
    else:
        weight_next = weight_now + [0, 1]
    return weight_next


N = 10 ** 1
weight_1 = np.array([2 ** 0.5, 1])
weight_2 = np.array([2 ** 0.5, 1])
utility = np.array([5, 6, 3, 4])  # 此时对手有占优策略 所有我会一直出b
Learner_strategy_1 = np.zeros(N)
Learner_strategy_2 = np.zeros(N)
Adversary_strategy_1 = np.zeros(N)
Adversary_strategy_2 = np.zeros(N)
for i in range(N):
    Adversary_strategy_2[i] = 0

Adversary_strategy_1[0] = random.randint(0, 1)
Learner_strategy_1[0] = br(weight_1[0] / sum(weight_1))
Learner_strategy_2[0] = br(weight_2[0] / sum(weight_2))
weight_1 = weight_update(Adversary_strategy_1[0], weight_1)
weight_2 = weight_update(Adversary_strategy_2[0], weight_2)
test_train = np.array([Learner_strategy_1[0], Adversary_strategy_1[0]])
average_utility_1 = np.zeros(N)     #剥削策略的平均效用
average_utility_2 = np.zeros(N)     #采取均衡策略的平均效用
sum1 = utility[int(2 * Learner_strategy_1[0] + Adversary_strategy_1[0])]    #剥削策略的总效用
sum2 = utility[int(2 * Learner_strategy_2[0] + Adversary_strategy_2[0])]    #采取均衡策略的总效用
average_utility_1[0] = sum1
average_utility_2[0] = sum2
for i in range(1, N):
    test_input = np.reshape(test_train, (i, 1, 2))
    restored_model = tf.keras.models.load_model('/home/dhc/model/' + 'my_model' + str(i) + '.h5')
    res = restored_model.predict(test_input)
    if res[i-1, 0] > 0.5 and res[i-1, 1] > 0.5:
        Adversary_strategy_1[i] = 0
    else:
        Adversary_strategy_1[i] = 1
    Learner_strategy_1[i] = br(weight_1[0] / sum(weight_1))
    Learner_strategy_2[i] = br(weight_2[0] / sum(weight_2))
    sum1 = sum1 + utility[int(2 * Learner_strategy_1[i] + Adversary_strategy_1[i])]
    sum2 = sum2 + utility[int(2 * Learner_strategy_2[i] + Adversary_strategy_2[i])]
    average_utility_1[i] = sum1 / (i + 1)
    average_utility_2[i] = sum2 / (i + 1)
    weight_1 = weight_update(Adversary_strategy_1[i], weight_1)
    weight_2 = weight_update(Adversary_strategy_2[i], weight_2)
    test_train = np.append(test_train, [Learner_strategy_1[i], Adversary_strategy_1[i]], 0)


print(average_utility_1)
print(average_utility_2)
plt.plot(average_utility_1, label='exploitation opponent', color='red')
plt.plot(average_utility_2, label='take nash equilibrium', color='purple')
plt.legend()
plt.xlabel('time')
plt.ylabel('average utility')
plt.show()